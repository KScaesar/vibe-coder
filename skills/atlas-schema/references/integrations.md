# Atlas-Schema - Integrations

**Pages:** 7

---

## The Atlas Terraform Provider

**URL:** https://atlasgo.io/integrations/terraform-provider

**Contents:**
- The Atlas Terraform Provider
  - Supported Workflowsâ€‹
      - Versioned Migrations
      - Declarative Migrations
  - Guidesâ€‹
      - Ad-hoc Approval
      - Project Configuration

The Atlas Terraform Provider enables you to manage your database schema as part of your Infrastructure-as-Code workflows using Terraform. With the provider, you can define your desired schema state and apply it to your database using Terraform resources.

Get started with the Atlas Terraform Provider

Manage your schema changes through versioned migration files. Use the atlas migrate diff command to generate migrations, atlas migrate apply to apply them, and integrate Atlas into your CI/CD pipeline for safe, auditable deployments.

Manage your schema declaratively by defining the desired state as code, and let Atlas plan and apply the changes using atlas schema apply. To review or approve changes before applying them, use atlas schema plan to pre-plan and approve migrations in advance.

Learn how to support ad-hoc approvals for declarative schema changes.

Learn how to use Atlas Project Configuration with the Atlas Terraform Provider.

---

## Automate Database CI/CD with Azure DevOps

**URL:** https://atlasgo.io/integrations/azure-devops

**Contents:**
- Automate Database CI/CD with Azure DevOps
- migrate applyâ€‹
  - Usageâ€‹
  - Inputsâ€‹
  - Outputsâ€‹
- migrate autorebaseâ€‹
  - Inputsâ€‹
- migrate diffâ€‹
  - Inputsâ€‹
  - Outputsâ€‹

Atlas provides an Azure DevOps extension with the AtlasAction task to run actions on Azure Pipelines. We recommend setting the githubConnection input to allow the task to report results to GitHub.

This reference guide documents the inputs and outputs for each AtlasAction task. For complete CI/CD workflow setup guides, see:

In each example below, $(ATLAS_TOKEN) is the secret that holds the Atlas Token to authenticate with Atlas Cloud.

To access the outputs generated by the task, you need to name your steps in the pipeline. See how to access task outputs.

Applies a migration directory on a target database

Add azure-pipelines.yml to your repo with the following contents:

Deploy a directory from the git repository

Deploy a directory from the cloud

The AtlasAction task will generate the following outputs for this action:

Automatically resolves atlas.sum conflicts and rebases the migration directory onto the target branch.

Automatically generate versioned migrations whenever the schema is changed, and commit them to the migration directory.

The AtlasAction task will generate the following outputs for this action:

Reverts deployed migration files on a target database

The AtlasAction task will generate the following outputs for this action:

CI for database schema changes with Atlas

Add azure-pipelines.yml to your repo with the following contents:

The AtlasAction task will generate the following outputs for this action:

Push the current version of your migration directory to Atlas Cloud.

Add azure-pipelines.yml to your repo with the following contents:

CI for database schema changes with Atlas

Sync the database schema to Atlas Cloud.

The AtlasAction task will generate the following outputs for this action:

Applies schema changes to a target database

Add azure-pipelines.yml to your repo with the following contents:

The AtlasAction task will generate the following outputs for this action:

Lint database schema with Atlas

Plan a declarative migration to move from the current state to the desired state

Add azure-pipelines.yml to your repo with the following contents:

The AtlasAction task will generate the following outputs for this action:

Approve a migration plan by its URL

Add azure-pipelines.yml to your repo with the following contents:

The AtlasAction task will generate the following outputs for this action:

Push a schema version with an optional tag to Atlas

Add azure-pipelines.yml to your repo with the following contents:

The AtlasAction task will generate the following outputs for this action:

Run schema tests against the desired schema

**Examples:**

Example 1 (yaml):
```yaml
trigger:- masterpool:  vmImage: ubuntu-lateststeps:- script: curl -sSf https://atlasgo.sh | sh  displayName: Install Atlas- script: atlas login --token $(ATLAS_TOKEN)  displayName: Atlas Login- task: AtlasAction@1  inputs:    action: 'migrate apply' # Required    url: $(DatabaseURL)    dir: 'file://migrations'
```

Example 2 (yaml):
```yaml
trigger:- masterpool:  vmImage: ubuntu-lateststeps:- script: curl -sSf https://atlasgo.sh | sh  displayName: Install Atlas- script: atlas login --token $(ATLAS_TOKEN)  displayName: Atlas Login- task: AtlasAction@1  inputs:    action: 'migrate apply' # Required    url: $(DatabaseURL)    dir: 'atlas://my-project'
```

Example 3 (yaml):
```yaml
trigger:- masterpool:  vmImage: ubuntu-lateststeps:- script: curl -sSf https://atlasgo.sh | sh  displayName: Install Atlas- script: atlas login --token $(ATLAS_TOKEN)  displayName: Atlas Login- task: AtlasAction@1  inputs:    action: 'migrate lint' # Required    dir_name: 'my-project'    env: 'ci'    dev_url: 'docker://mysql/8/dev'    githubConnection: '<Connection to your GitHub>'
```

Example 4 (yaml):
```yaml
trigger:- masterpool:  vmImage: ubuntu-lateststeps:- script: curl -sSf https://atlasgo.sh | sh  displayName: Install Atlas- script: atlas login --token $(ATLAS_TOKEN)  displayName: Atlas Login- task: AtlasAction@1  inputs:    action: 'migrate lint' # Required    dir_name: 'my-project'    env: 'ci'    dev_url: 'docker://postgres/15/dev?search_path=public'    githubConnection: '<Connection to your GitHub>'
```

---

## Automate Database CI/CD with GitLab Pipelines

**URL:** https://atlasgo.io/integrations/gitlab-ci-components

**Contents:**
- Automate Database CI/CD with GitLab Pipelines
- migrate-pushâ€‹
  - Usageâ€‹
  - Inputsâ€‹
- migrate-lintâ€‹
  - Usageâ€‹
  - Inputsâ€‹
- migrate-applyâ€‹
  - Usageâ€‹
    - Deploy a directory from the git repositoryâ€‹

GitLab CI is an automation tool integrated into GitLab that helps streamline code testing, building, and deployment through configurable pipelines. Using a .gitlab-ci.yml file, developers define jobs and stages that GitLab executes automatically, enabling consistent integration and delivery workflows.

Atlas provides CI/CD components for easy integration in any project. Click here to see the full list of components in the CI/CD catalog.

Check out this guide for full examples of the versioned and declarative flows using the GitLab components.

To use the components in a self-hosted instance, you must mirror the component project.

Pushes a migration directory to the cloud.

Use this component to lint new migration files in any merge request.

Use this component to deploy migration files to your database directly from your CI runner. You can either deploy a local directory (i.e from your git repository) or a directory stored in Atlas Cloud.

Atlas needs network access to your database to deploy migrations, so make sure your database is either publicly accessible or that you have otherwise running this component from a runner that has network access to your database.

Use this component to automatically generate versioned migrations whenever the schema is changed, and commit them to the migration directory.

Creates a plan for a declarative schema change. Read more about pre-planning schema changes here.

To enable Atlas comments on merge requests, you need create an access token with appropriate role and permissions, set it as a CI/CD variable and pass it to the component in the "gitlab-token" input. See the usage example below:

Approves a pending plan in Atlas Cloud for a specific change (i.e. the diff between the current and desired states). Run this job on the main branch of your project to automatically approve plans that were generated by the schema-plan job in previous merge requests.

If more than one pending plan is found for a given change, the job will exit with a non-zero code. In this case you will need to Choose the prefered plan and delete the others, before re-runnig the job.

Pushes a declarative schema to the cloud.

Use this component to apply a schema to your database directly from your CI runner. You can either deploy a local state (i.e from your git repository) or a schema stored in Atlas Cloud.

Atlas needs network access to your database to deploy migrations, so make sure your database is either publicly accessible or that you have otherwise running this component from a runner that has network access to your database.

Monitor changes of the database schema and track them in Atlas Cloud. Read more about schema monitoring here.

Atlas needs network access to your database to monitor schema changes, so make sure your database is either publicly accessible or that you have otherwise running this component from a runner that has network access to your database.

To run on a schedule, go to the Build tab in your repository, Go to the Pipeline Schedules tab and click on New Schedule.

**Examples:**

Example 1 (yaml):
```yaml
services:  - mysql:latestvariables:  MYSQL_DATABASE: dev  MYSQL_ROOT_PASSWORD: passstages:  - pushinclude:  - component: $CI_SERVER_FQDN/arigaio/atlas/migrate-push@~latest    inputs:      stage: push      dir: 'file://migrations'      dir-name: 'my-project'      dev-url: 'mysql://root:pass@mysql:3306/dev'      atlas-cloud-token: $ATLAS_CLOUD_TOKEN
```

Example 2 (yaml):
```yaml
services:  - mariadb:latestvariables:  MYSQL_DATABASE: dev  MYSQL_ROOT_PASSWORD: passstages:  - pushinclude:  - component: $CI_SERVER_FQDN/arigaio/atlas/migrate-push@~latest    inputs:      stage: push      dir: 'file://migrations'      dir-name: 'my-project'      dev-url: 'maria://root:pass@mariadb:3306/dev'      atlas-cloud-token: $ATLAS_CLOUD_TOKEN
```

Example 3 (yaml):
```yaml
services:  - postgres:latestvariables:  POSTGRES_DB: dev  POSTGRES_USER: postgres  POSTGRES_PASSWORD: passstages:  - pushinclude:  - component: $CI_SERVER_FQDN/arigaio/atlas/migrate-push@~latest    inputs:      stage: push      dir: 'file://migrations'      dir-name: 'my-project'      dev-url: 'postgres://postgres:pass@postgres/dev?sslmode=disable'      atlas-cloud-token: $ATLAS_CLOUD_TOKEN
```

Example 4 (yaml):
```yaml
stages:  - pushinclude:  - component: $CI_SERVER_FQDN/arigaio/atlas/migrate-push@~latest    inputs:      stage: push      dir: 'file://migrations'      dir-name: 'my-project'      dev-url: 'sqlite://db?mode-memory'      atlas-cloud-token: $ATLAS_CLOUD_TOKEN
```

---

## Automate Database CI/CD with CircleCI Orbs

**URL:** https://atlasgo.io/integrations/circleci-orbs

**Contents:**
- Automate Database CI/CD with CircleCI Orbs
- atlas-orb/setupâ€‹
  - Usageâ€‹
  - Inputsâ€‹
- atlas-orb/migrate_pushâ€‹
  - Usageâ€‹
  - Inputsâ€‹
- atlas-orb/migrate_lint (Required atlas login)â€‹
  - Usageâ€‹
  - Inputsâ€‹

CircleCI Orbs are reusable packages of CircleCI configuration that can be shared across projects. They provide a way to simplify your CircleCI configuration by encapsulating common tasks into a single line of code.

Atlas provides a number of Orbs to help you integrate Atlas into your CircleCI workflows.

The atlas-orb/setup action can be used to install the Atlas CLI and authenticate with Atlas Cloud.

Push the current version of your migration directory to Atlas Cloud.

All inputs are optional as they may be specified in the Atlas configuration file.

Teams using CircleCI that wish to ensure all changes to their database schema are safe can use the atlas-orb/migrate_lint CircleCI Orb.

This action is used for linting migration directories using the atlas migrate lint command. This command validates and analyzes the contents of migration directories and generates insights and diagnostics on the selected changes:

Add .circleci/config.yml to your repo with the following contents:

All inputs are optional as they may be specified in the Atlas configuration file.

The GITHUB_TOKEN and GITHUB_REPOSITORY environment variables are required for the atlas-orb/migrate_lint action to work. These variables are used to post lint results to the GitHub Pull Request as comments. If you want to use a different environment variable name, you can specify it using the github_token_env and github_repository_env inputs

Push the current version of your migration directory to Atlas Cloud.

All inputs are optional as they may be specified in the Atlas configuration file.

Revert migrations to a database.

All inputs are optional as they may be specified in the Atlas configuration file.

Test migrations on a database.

All inputs are optional as they may be specified in the Atlas configuration file.

The atlas-orb/migrate_autorebase Automatically resolves atlas.sum conflicts and rebases the migration directory onto the target branch.

Test schema on a database.

All inputs are optional as they may be specified in the Atlas configuration file.

**Examples:**

Example 1 (yaml):
```yaml
version: 2.1orbs:  atlas-orb: ariga/atlas-orb@0.0.6jobs:  push-dir:    environment:      # Define those envs in CircleCI context to keep them secure      ATLAS_TOKEN: "your-atlas-token"    steps:      - checkout      - atlas-orb/setup:          version: "latest"workflows:  use-atlas:    jobs:      - push-dir
```

Example 2 (yaml):
```yaml
version: 2.1orbs:  atlas-orb: ariga/atlas-orb@0.0.6jobs:  push-dir:    docker:      - image: cimg/base:current      - image: cimg/mysql:8        environment:          MYSQL_DATABASE: dev          MYSQL_ROOT_PASSWORD: pass    environment:      # Define those envs in CircleCI context to keep them secure      ATLAS_TOKEN: "your-atlas-token"    steps:      - checkout      - run:          name: Wait for MySQL          command: dockerize -wait tcp://127.0.0.1:3306 -timeout 60s      - atlas-orb/setup:          version: "latest"      - atlas-orb/migrate_push:          dir_name: my-project          dev_url: "mysql://root:pass@localhost:3306/dev"workflows:  use-atlas:    jobs:      - push-dir
```

Example 3 (yaml):
```yaml
version: 2.1orbs:  atlas-orb: ariga/atlas-orb@0.0.6jobs:  push-dir:    docker:      - image: cimg/base:current      - image: cimg/mariadb:10.6        environment:          MYSQL_DATABASE: dev          MYSQL_ROOT_PASSWORD: pass    environment:      # Define those envs in CircleCI context to keep them secure      ATLAS_TOKEN: "your-atlas-token"    steps:      - checkout      - run:          name: Wait for MariaDB          command: dockerize -wait tcp://127.0.0.1:3306 -timeout 60s      - atlas-orb/setup:          version: "latest"      - atlas-orb/migrate_push:          dir_name: my-project          dev_url: "maria://root:pass@localhost:3306/dev"workflows:  use-atlas:    jobs:      - push-dir
```

Example 4 (yaml):
```yaml
version: 2.1orbs:  atlas-orb: ariga/atlas-orb@0.0.6jobs:  push-dir:    docker:      - image: cimg/base:current      - image: cimg/postgres:15.0        environment:          POSTGRES_DB: dev          POSTGRES_PASSWORD: pass    environment:      # Define those envs in CircleCI context to keep them secure      ATLAS_TOKEN: "your-atlas-token"    steps:      - checkout      - run:          name: Wait for Postgres          command: dockerize -wait tcp://127.0.0.1:5432 -timeout 60s      - atlas-orb/setup:          version: "latest"      - atlas-orb/migrate_push:          dir_name: my-project          dev_url: "postgres://postgres:pass@localhost:5432/dev?sslmode=disable"workflows:  use-atlas:    jobs:      - push-dir
```

---

## Automate Database CI/CD with GitHub Actions

**URL:** https://atlasgo.io/integrations/github-actions

**Contents:**
- Automate Database CI/CD with GitHub Actions
- ariga/setup-atlasâ€‹
  - Usageâ€‹
  - Inputsâ€‹
- ariga/atlas-action/migrate/pushâ€‹
  - Usageâ€‹
  - Inputsâ€‹
  - Outputsâ€‹
- ariga/atlas-action/migrate/lintâ€‹
  - Usageâ€‹

GitHub Actions is a popular CI/CD product from GitHub. With GitHub Actions, users can easily define workflows that are triggered in various lifecycle events related to a Git repository. For example, many teams configure GitHub actions to run all unit tests in a repository on each change that is committed to a repository.

One of the powerful features of GitHub Actions is its extensibility: it is very easy to package a piece of functionality as a module (called an "action") that can later be re-used by many projects.

Atlas provides a number of GitHub Actions that can be used to automate database schema management tasks.

The ariga/setup-atlas action can be used to install Atlas from a GitHub Actions workflow.

Push the current version of your migration directory to Atlas Cloud.

All inputs are optional as they may be specified in the Atlas configuration file.

Teams using GitHub that wish to ensure all changes to their database schema are safe can use the atlas-action/migrate/lint GitHub Action.

This action is used for linting migration directories using the atlas migrate lint command. This command validates and analyzes the contents of migration directories and generates insights and diagnostics on the selected changes:

Add .github/workflows/atlas-ci.yaml to your repo with the following contents:

All inputs are optional as they may be specified in the Atlas configuration file.

You can use ariga/atlas-action/migrate-apply to deploy migrations to your database directly from GitHub Actions.

Atlas needs network access to your database to deploy migrations, so make sure your database is either publicly accessible or that you have otherwise enabled network access to it from your GitHub Actions runners.

This action supports two workflows:

Notice that the following examples rely on a DATABASE_URL secret being set in your repository.

To learn how to set secrets, read GitHub's documentation.

The DATABASE_URL secret should be set to the URL of your database, for examples please see Atlas URL formats.

All inputs are optional as they may be specified in the Atlas configuration file.

Revert migrations to a database.

Add .github/workflows/atlas-ci.yaml to your repo with the following contents:

All inputs are optional as they may be specified in the Atlas configuration file.

Test migrations on a database.

Add .github/workflows/atlas-ci.yaml to your repo with the following contents:

All inputs are optional as they may be specified in the Atlas configuration file.

Automatically resolves atlas.sum conflicts and rebases the migration directory onto the target branch.

Users should set the migrate/lint action to ensure no logical conflicts occur after this action.

After the rebase is done and a commit is pushed by the action, no other workflows will be triggered unless the action is running with a personal access token (PAT).

Add .github/workflows/atlas-rebase.yaml to your repo with the following contents:

dir, to and dev-url are required, but they can be specified in the Atlas configuration file via config and env.

Automatically generate versioned migrations whenever the schema is changed, and commit them to the migration directory.

After committing the changes to the migration directory, no other workflows will be triggered unless the action is run with a personal access token (PAT).

Add .github/workflows/atlas-ci.yaml to your repo with the following contents:

dir, to and dev-url are required, but they can be specified in the Atlas configuration file via config and env.

Test schema on a database.

Add .github/workflows/atlas-ci.yaml to your repo with the following contents:

All inputs are optional as they may be specified in the Atlas configuration file.

Lint a schema to ensure it is valid and follows best practices.

Add .github/workflows/atlas-ci.yaml to your repo with the following contents:

url and dev-url are required, but they can be specified in the Atlas configuration file via config and env.

Apply a declarative migrations to a database. See a full example of declarative workflow.

Push a schema to Atlas Registry with an optional tag.

Plan a declarative migration for a schema transition.

Approve a declarative migration plan.

Monitor changes of the database schema and track them in Atlas Cloud. Can be used periodically to monitor changes in the database schema.

**Examples:**

Example 1 (yaml):
```yaml
name: Deploy schema changesrun-name: I'm using Atlas ðŸš€on: [push]jobs:  use-atlas:    runs-on: ubuntu-latest    steps:      - uses: ariga/setup-atlas@v0        with:          cloud-token: ${{ secrets.ATLAS_CLOUD_TOKEN }}      - run: atlas version      # - run: atlas schema apply ...
```

Example 2 (yaml):
```yaml
name: Push Migrationson:  # Run whenever code is changed in the master branch,  # change this to your main branch.  push:    branches:      - masterjobs:  push:    services:      # Spin up a mysql:8 container to be used as the dev-database.      mysql:        image: mysql:8        env:          MYSQL_DATABASE: dev          MYSQL_ROOT_PASSWORD: pass        ports:          - 3306:3306        options: >-          --health-cmd "mysqladmin ping -ppass"          --health-interval 10s          --health-start-period 10s          --health-timeout 5s          --health-retries 10    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v3      - uses: ariga/setup-atlas@v0        with:          cloud-token: ${{ secrets.ATLAS_CLOUD_TOKEN }}      - uses: ariga/atlas-action/migrate/push@v1        with:          dir: 'file://migrations'          dir-name: 'my-project'          dev-url: 'mysql://root:pass@localhost:3306/dev'
```

Example 3 (yaml):
```yaml
name: Push Migrationson:  # Run whenever code is changed in the master branch,  # change this to your main branch.  push:    branches:      - masterjobs:  push:    services:      # Spin up a mariadb:11 container to be used as the dev-database.      maria11:        image: mariadb:11        env:          MYSQL_DATABASE: dev          MYSQL_ROOT_PASSWORD: pass        ports:          - 3306:3306        options: >-          --health-cmd "mysqladmin ping -ppass"          --health-interval 10s          --health-start-period 10s          --health-timeout 5s          --health-retries 10    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v3      - uses: ariga/setup-atlas@v0        with:          cloud-token: ${{ secrets.ATLAS_CLOUD_TOKEN }}      - uses: ariga/atlas-action/migrate/push@v1        with:          dir: 'file://migrations'          dir-name: 'my-project'          dev-url: 'maria://root:pass@localhost:3306/dev'
```

Example 4 (yaml):
```yaml
name: Push Migrationson:  # Run whenever code is changed in the master branch,  # change this to your root branch.  push:    branches:      - masterjobs:  push:    services:      # Spin up a postgres:15 container to be used as the dev-database.      postgres15:        image: postgres:15        env:          POSTGRES_DB: test          POSTGRES_PASSWORD: pass        ports:          - 5432:5432        options: >-          --health-cmd pg_isready          --health-interval 10s          --health-timeout 5s          --health-retries 5    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v3      - uses: ariga/setup-atlas@v0        with:          cloud-token: ${{ secrets.ATLAS_CLOUD_TOKEN }}      - uses: ariga/atlas-action/migrate/push@v1        with:          dir: 'file://migrations'          dir-name: 'my-project'          dev-url: postgres://postgres:pass@localhost:5432/test?sslmode=disable
```

---

## Bitbucket Pipes

**URL:** https://atlasgo.io/integrations/bitbucket-pipes

**Contents:**
- Bitbucket Pipes
- migrate/applyâ€‹
  - Usageâ€‹
  - Inputsâ€‹
  - Outputsâ€‹
- migrate/autorebaseâ€‹
  - Inputsâ€‹
- migrate/diffâ€‹
  - Inputsâ€‹
  - Outputsâ€‹

Atlas provides seamless integration with Bitbucket Pipelines, allowing you to manage and apply database migrations directly from your Bitbucket repository. By leveraging Bitbucket Pipelines, you can automate the deployment of migration directories to your target databases, ensuring that your database schema is always up-to-date with your application code.

This guide will walk you through the steps to set up and use Atlas-Action with Bitbucket Pipelines, enabling you to deploy migration directories from your git repository effortlessly.

Run migrations on a target database using migrate apply

Add bitbucket-pipelines.yml to your repo with the following contents:

Deploy a directory from the git repository

Deploy a directory from the cloud

The outputs are written into the .atlas-action/outputs.sh, we can load it for the next step using the source command.

Automatically resolves atlas.sum conflicts and rebases the migration directory onto the target branch.

Automatically generate versioned migrations whenever the schema is changed, and commit them to the migration directory.

The outputs are written into the .atlas-action/outputs.sh, we can load it for the next step using the source command.

Reverts deployed migration files from a target database using migrate down

The outputs are written into the .atlas-action/outputs.sh, we can load it for the next step using the source command.

Verify migration safety using migration linting.

Add bitbucket-pipelines.yml to your repo with the following contents:

The outputs are written into the .atlas-action/outputs.sh, we can load it for the next step using the source command.

Push the current version of your migration directory to the schema registry

Add bitbucket-pipelines.yml to your repo with the following contents:

Run migration testing in CI.

Run schema monitoring for a target database, pushes the schema to the schema registry.

The outputs are written into the .atlas-action/outputs.sh, we can load it for the next step using the source command.

Apply the desired schema to the target database using declarative migrations.

Add bitbucket-pipelines.yml to your repo with the following contents:

The outputs are written into the .atlas-action/outputs.sh, we can load it for the next step using the source command.

Lint database schema with Atlas

Plan a declarative migration to move from the current state to the desired state using schema plan

Add bitbucket-pipelines.yml to your repo with the following contents:

The outputs are written into the .atlas-action/outputs.sh, we can load it for the next step using the source command.

Approve a migration plan by its URL

Add bitbucket-pipelines.yml to your repo with the following contents:

The outputs are written into the .atlas-action/outputs.sh, we can load it for the next step using the source command.

Push a schema version with an optional tag to Atlas

Add bitbucket-pipelines.yml to your repo with the following contents:

The outputs are written into the .atlas-action/outputs.sh, we can load it for the next step using the source command.

Run schema tests against the desired schema

**Examples:**

Example 1 (yaml):
```yaml
image: atlassian/default-image:3pipelines:  branches:    master:      - step:          name: "Applies a migration directory on a target database"          script:            - name: "Migrate Apply"              pipe: docker://arigaio/atlas-action:v1              variables:                ATLAS_ACTION: "migrate/apply" # Required                ATLAS_INPUT_URL: ${DATABASE_URL}                ATLAS_INPUT_DIR: "file://migrations"            - source .atlas-action/outputs.sh
```

Example 2 (yaml):
```yaml
image: atlassian/default-image:3pipelines:  branches:    master:      - step:          name: "Applies a migration directory on a target database"          script:            - name: "Migrate Apply"              pipe: docker://arigaio/atlas-action:v1              variables:                ATLAS_ACTION: "migrate/apply" # Required                ATLAS_TOKEN: ${ATLAS_TOKEN}                ATLAS_INPUT_URL: ${DATABASE_URL}                ATLAS_INPUT_DIR: "atlas://my-project"            - source .atlas-action/outputs.sh
```

Example 3 (yaml):
```yaml
image: atlassian/default-image:3pipelines:  branches:    master:      - step:          name: "CI for database schema changes with Atlas"          script:            - name: "Migrate Lint"              pipe: docker://arigaio/atlas-action:v1              variables:                ATLAS_ACTION: "migrate/lint" # Required                ATLAS_TOKEN: ${ATLAS_TOKEN}                BITBUCKET_ACCESS_TOKEN: ${BITBUCKET_ACCESS_TOKEN}                ATLAS_INPUT_DIR_NAME: "my-project"                ATLAS_INPUT_DEV_URL: "docker://mysql/8/dev"            - source .atlas-action/outputs.sh
```

Example 4 (yaml):
```yaml
image: atlassian/default-image:3pipelines:  branches:    master:      - step:          name: "CI for database schema changes with Atlas"          script:            - name: "Migrate Lint"              pipe: docker://arigaio/atlas-action:v1              variables:                ATLAS_ACTION: "migrate/lint" # Required                ATLAS_TOKEN: ${ATLAS_TOKEN}                BITBUCKET_ACCESS_TOKEN: ${BITBUCKET_ACCESS_TOKEN}                ATLAS_INPUT_DIR_NAME: "my-project"                ATLAS_INPUT_DEV_URL: "docker://postgres/15/dev?search_path=public"            - source .atlas-action/outputs.sh
```

---

## The Atlas Kubernetes Operator

**URL:** https://atlasgo.io/integrations/kubernetes

**Contents:**
- The Atlas Kubernetes Operator
  - Supported Workflowsâ€‹
      - Declarative Migrations
      - Versioned Migrations
  - Guidesâ€‹
      - Installation
      - Pre-approval
      - Ad-hoc Approval
      - Using SSL Certs
      - Project Configuration

The Atlas Kubernetes Operator is a Kubernetes controller that uses Atlas to manage your database schema. Using the Operator you can define the desired schema and apply it to your database using the Kubernetes API.

Get started with the Atlas Operator

Manage your schema declaratively by defining the desired state as code, and let Atlas plan and apply the changes using atlas schema apply. To review or approve changes before applying them, use atlas schema plan to pre-plan and approve migrations in advance.

Manage your schema changes through versioned migration files. Use the atlas migrate diff command to generate migrations, atlas migrate apply to apply them, and integrate Atlas into your CI/CD pipeline for safe, auditable deployments.

Installing the Operator with advanced configurations.

Learn how to set up pre-approval flows for declarative migrations.

Learn how to support ad-hoc approvals for declarative schema changes.

Use SSL certificates to establish an encrypted connection to your database

Inject your configuration into the Atlas Operator.

---
